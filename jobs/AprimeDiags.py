import os
import sys
import logging
import time
import re

from pprint import pformat
from subprocess import Popen, PIPE
from time import sleep
from random import randint
from datetime import datetime
from shutil import copyfile

from lib.util import render
from lib.util import print_message
from lib.util import print_debug
from lib.util import cmd_exists
from lib.util import create_symlink_dir
from lib.events import Event_list
from lib.slurm import Slurm
from JobStatus import JobStatus, StatusMap


class AprimeDiags(object):
    def __init__(self, config, event_list):
        """
        Setup class attributes
        """
        self.event_list = event_list
        self.inputs = {
            'mpaso_regions_file': '',
            'web_dir': '',
            'host_url': '',
            'mpas_am_dir': '',
            'rpt_dir': '',
            'mpas_cice_dir': '',
            'mpas_o_dir': '',
            'streams_dir': '',
            'host_url_prefix': '',
            'host_directory': '',
            'run_id': '',
            'year_set': '',
            'climo_temp_dir': '',
            'coupled_project_dir': '',
            'test_casename': '',
            'test_native_res': '',
            'test_archive_dir': '',
            'test_begin_yr_climo': '',
            'test_end_yr_climo': '',
            'test_begin_yr_ts': '',
            'test_end_yr_ts': '',
            'ref_case': '',
            'ref_archive_dir': '',
            'mpas_meshfile': '',
            'mpas_remapfile': '',
            'mpas_cice_in_dir': '',
            'pop_remapfile': '',
            'remap_files_dir': '',
            'GPCP_regrid_wgt_file': '',
            'CERES_EBAF_regrid_wgt_file': '',
            'ERS_regrid_wgt_file': '',
            'coupled_home_directory': '',
            'coupled_template_path': '',
            'rendered_output_path': '',
            'obs_ocndir': '',
            'obs_seaicedir': '',
            'obs_sstdir': '',
            'dataset_name': '',
            'output_base_dir': '',
            'run_scripts_path': '',
            'mpas_rst_dir': '',
            'run_ocean': '',
            'experiment': ''
        }
        self.slurm_args = {
            'num_cores': '-n 16', # 16 cores
            'run_time': '-t 0-02:00', # 1 hour run time
            'num_machines': '-N 1', # run on one machine
            'oversubscribe': '--oversubscribe'
        }
        config['run_ocean'] = int(config['run_ocean'])
        self.start_time = None
        self.end_time = None
        self.config = {}
        self.status = JobStatus.INVALID
        self._type = 'aprime_diags'
        self.outputs = {}
        self.year_set = config.get('yearset', 0)
        self.start_year = config['start_year']
        self.end_year = config['end_year']
        self.job_id = 0
        self.depends_on = []
        self.prevalidate(config)

    def __str__(self):
        return pformat({
            'type': self.type,
            'config': self.config,
            'status': self.status,
            'depends_on': self.depends_on,
            'job_id': self.job_id,
            'year_set': self.year_set
        })

    @property
    def type(self):
        return self._type

    @property
    def status(self):
        return self._status

    @status.setter
    def status(self, status):
        self._status = status

    def prevalidate(self, config):
        """
        Iterate over given config dictionary making sure all the inputs are set
        and rejecting any inputs that arent in the input dict
        """
        self.config = config
        self.depends_on = config.get('depends_on')
        self.year_set = config.get('year_set')
        self.status = JobStatus.VALID

        if not os.path.exists(self.config.get('run_scripts_path')):
            os.makedirs(self.config.get('run_scripts_path'))
        if self.year_set == 0:
            self.status = JobStatus.INVALID

    def postvalidate(self):
        """
        Check that what the job was supposed to do actually happened
        returns 1 if the job is done, 0 otherwise
        """
        # find the directory generated by coupled diags
        output_path = self.config.get('output_base_dir')
        if not os.path.exists(output_path):
            return False
        try:
            output_contents = os.listdir(output_path)
        except IOError:
            return False
        if not output_contents:
            return False
        output_directory = None
        for item in output_contents:
            if item.split('-')[-1] == 'obs':
                output_directory = item
        if not output_directory:
            return False
        output_directory = os.path.join(output_path, output_directory)
        if os.path.exists(output_directory):
            contents = os.listdir(output_directory)
            target_output = 35
            if self.config['run_ocean']:
                target_output = 60
            return bool(len(contents) >= target_output)
        else:
            return False

    def setup_input_directory(self):
        climo_temp_path = self.config.get('climo_tmp_dir')
        set_start_year = self.config.get('start_year')
        set_end_year = self.config.get('end_year')

        if not climo_temp_path or not os.path.exists(climo_temp_path):
            self.status = JobStatus.INVALID
            msg = '{} does not exist'.format(climo_temp_path)
            logging.error(mgs)
            return False

        run_dir = os.path.join(
            self.config.get('test_archive_dir'),
            self.config.get('test_casename'),
            'run')
        if not os.path.exists(run_dir):
            os.makedirs(run_dir)

        # create atm links
        climo_src_list = os.listdir(climo_temp_path)
        create_symlink_dir(
            src_dir=climo_temp_path,
            src_list=climo_src_list,
            dst=run_dir)
        # create mpaso.hist.am links and mpascice links
        if self.config.get('run_ocean'):
            for mpas_dir in ['mpas_am_dir', 'mpas_cice_dir']:
                mpas_temp_list = []
                all_years = []
                mpas_path = self.config.get(mpas_dir)
                if not mpas_path:
                    msg = 'Run ocean set to 1, but no mpas files included. Invalid configuration'
                    self.event_list.push(message=msg)
                    logging.error(mgs)
                    self.status = JobStatus.INVALID
                    return 2
                for mpas in os.listdir(mpas_path):
                    start = re.search(r'\.\d\d\d\d', mpas)
                    s_index = start.start() + 1
                    year = int(mpas[s_index: s_index + 4])
                    if year > set_end_year or year < set_start_year:
                        if year == set_end_year + 1:
                            month = int(mpas[s_index + 5: s_index + 7])
                            if month == 1:
                                mpas_temp_list.append(mpas)
                        continue
                    mpas_temp_list.append(mpas)
                    if year not in all_years:
                        all_years.append(year)

            if len(all_years) < (set_end_year - set_start_year):
                msg = 'len({all_years}) < ({set_end_year} - {set_start_year})'.format(
                    all_years=all_years, set_end_year=set_end_year, set_start_year=set_start_year)
                loggig.error(msg)
                return False
            create_symlink_dir(
                src_dir=mpas_path,
                src_list=mpas_temp_list,
                dst=run_dir)

        extras = ['mpas_am_dir', 'mpas_cice_in_dir', 'mpas_o_dir', 'streams_dir', 'mpas_rst_dir', 'rpt_dir']
        for extra in extras:
            path = self.config.get(extra)
            if not path or not os.path.exists(path):
                continue
            src_list = os.listdir(path)
            if not src_list:
                msg = '{} is empty'.format(path)
                logging.error(msg)
                return False
            create_symlink_dir(
                src_dir=path,
                src_list=src_list,
                dst=run_dir)
        return True

    def execute(self):
        """
        Perform the actual work
        """
        # First check if the job has already been completed
        if self.postvalidate():
            self.status = JobStatus.COMPLETED
            message = 'Coupled_diag job already computed, skipping'
            self.event_list.push(message=message)
            return 0

        self.start_time = datetime.now()
        # create symlinks to the input data
        setup_status = self.setup_input_directory()
        if not setup_status:
            return -1
        elif setup_status == 2:
            return False

        # render the run_AIMS.csh script
        template_out = self.config.get('rendered_output_path')
        render(
            variables=self.config,
            input_path=self.config.get('coupled_template_path'),
            output_path=template_out,
            delimiter='%%')
        run_script_template_out = os.path.join(
            self.config.get('run_scripts_path'), 'coupled_diag_{0}-{1}.csh'.format(
                self.config.get('start_year'),
                self.config.get('end_year')))
        copyfile(
            src=template_out,
            dst=run_script_template_out)

        cmd = 'csh {run_AIMS}'.format(
            run_AIMS=self.config.get('rendered_output_path'))

        expected_name = 'coupled_diag_set_{set}_{start}_{end}'.format(
            set=self.config.get('year_set'),
            start='{:04d}'.format(self.config.get('test_begin_yr_climo')),
            end='{:04d}'.format(self.config.get('test_end_yr_climo')))

        run_script = os.path.join(self.config.get('run_scripts_path'), expected_name)
        if os.path.exists(run_script):
            os.remove(run_script)

        self.slurm_args['out_file'] = '-o {out}'.format(
            out=run_script + '.out')
        self.slurm_args['working_dir'] = '--workdir {dir}'.format(
            dir=self.config.get('coupled_diags_home'))
        slurm_args = ['#SBATCH {}'.format(self.slurm_args[s]) for s in self.slurm_args]
        slurm_prefix = '\n'.join(slurm_args) + '\n'

        with open(run_script, 'w') as batchfile:
            batchfile.write('#!/bin/bash\n')
            batchfile.write(slurm_prefix)
            batchfile.write(cmd)

        slurm = Slurm()
        self.job_id = slurm.batch(run_script, '--oversubscribe')
        status = slurm.showjob(self.job_id)
        self.status = StatusMap[status.get('JobState')]
        message = "## {job} id: {id} changed status to {status}".format(
            job=self.type,
            id=self.job_id,
            status=self.status)
        logging.info(message)

        return self.job_id
